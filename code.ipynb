{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fafc289b-4623-40af-904d-a6184d8b733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL.ImageQt import ImageQt\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets, uic\n",
    "from PyQt5.QtWidgets import QWidget, QLabel\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "069cf160-e884-4aba-84db-a03a09984a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM trained with 2 samples\n",
      "SVM trained with 3 samples\n"
     ]
    }
   ],
   "source": [
    "def save_pickle(filename, data):\n",
    "    with open(filename, \"wb\") as fo:\n",
    "        pickle.dump(data, fo, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as fo:\n",
    "        return pickle.load(fo)\n",
    "\n",
    "# ---------------- Main App ----------------\n",
    "class GaitDemo(QtWidgets.QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        uic.loadUi(\"stridesentinelUI.ui\", self)\n",
    "        self.showFullScreen()\n",
    "\n",
    "        os.makedirs(\"gei\", exist_ok=True)\n",
    "\n",
    "        # Camera\n",
    "        self.capture = cv2.VideoCapture(0)\n",
    "        if not self.capture.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            sys.exit()\n",
    "\n",
    "        # Background subtractor\n",
    "        self.bg_sub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=40)\n",
    "\n",
    "        # States\n",
    "        self.register_state = False\n",
    "        self.recognition_state = False\n",
    "        self.save_on = False\n",
    "        self.gei_fix_num = 20\n",
    "        self.numInGEI = 0\n",
    "        self.gei_current = np.zeros((128, 88), np.single)\n",
    "\n",
    "        # Buttons\n",
    "        self.save_gei.clicked.connect(self.save_gei_f)\n",
    "        self.register_2.clicked.connect(self.register_show)\n",
    "        self.recognize.clicked.connect(self.recognition_show)\n",
    "        self.updater.clicked.connect(self.update_bk)\n",
    "\n",
    "        # Data & model\n",
    "        self.load_dataset()\n",
    "\n",
    "        # Timer\n",
    "        self._timer = QtCore.QTimer(self)\n",
    "        self._timer.timeout.connect(self.play)\n",
    "        self._timer.start(30)\n",
    "\n",
    "        self.show()\n",
    "\n",
    "    # ---------------- UI callbacks ----------------\n",
    "    def save_gei_f(self):\n",
    "        self.save_on = True\n",
    "        self.state_print.setPlainText('Saving!')\n",
    "\n",
    "    def register_show(self):\n",
    "        self.register_state = True\n",
    "        self.recognition_state = False\n",
    "        self.state_print.setPlainText('Register!')\n",
    "        self.gei_current = np.zeros((128, 88), np.single)\n",
    "        self.numInGEI = 0\n",
    "\n",
    "    def recognition_show(self):\n",
    "        if self.num < 2 or self.model is None:\n",
    "            self.state_print.setPlainText(\"Need at least 2 samples!\")\n",
    "            return\n",
    "        self.recognition_state = True\n",
    "        self.register_state = False\n",
    "        self.state_print.setPlainText('Recognize!')\n",
    "        self.gei_current = np.zeros((128, 88), np.single)\n",
    "        self.numInGEI = 0\n",
    "\n",
    "    # ---------------- Dataset & Model ----------------\n",
    "    def load_dataset(self):\n",
    "        self.data_path = './GaitData.pkl'\n",
    "        if QtCore.QFile.exists(self.data_path):\n",
    "            dic = load_pickle(self.data_path)\n",
    "            self.num = dic['num']\n",
    "            self.gei = dic['gei']\n",
    "            self.name = dic['name']\n",
    "        else:\n",
    "            self.num = 0\n",
    "            self.gei = np.zeros((0, 128, 88), np.uint8)\n",
    "            self.name = []\n",
    "            dic = {'num': self.num, 'gei': self.gei, 'name': self.name}\n",
    "            save_pickle(self.data_path, dic)\n",
    "\n",
    "        self.id_num.setPlainText('%d' % self.num)\n",
    "        self.state_print.setPlainText('Running!')\n",
    "        self.train_model()\n",
    "\n",
    "    def train_model(self):\n",
    "        self.model = None\n",
    "        if self.num >= 2:\n",
    "            X = self.gei[:self.num].reshape(self.num, -1)\n",
    "            y = np.array(self.name)\n",
    "            self.model = SVC(kernel='rbf', probability=True)\n",
    "            self.model.fit(X, y)\n",
    "            print(\"SVM trained with\", self.num, \"samples\")\n",
    "\n",
    "    # ---------------- Main loop ----------------\n",
    "    def play(self):\n",
    "        ret, frame = self.capture.read()\n",
    "        if not ret:\n",
    "            return\n",
    "\n",
    "        frame = cv2.resize(frame, (512, 384))\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        # Background subtraction\n",
    "        thresh = self.bg_sub.apply(gray)\n",
    "\n",
    "        # Morphology cleanup\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        max_rec = 0\n",
    "        x_max = y_max = w_max = h_max = 0\n",
    "\n",
    "        for c in cnts:\n",
    "            if cv2.contourArea(c) < 800:\n",
    "                continue\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            if w > 25 and h > 50 and w * h > max_rec:\n",
    "                max_rec = w * h\n",
    "                x_max, y_max, w_max, h_max = x, y, w, h\n",
    "\n",
    "        if max_rec > 0:\n",
    "            cv2.rectangle(frame, (x_max, y_max),\n",
    "                          (x_max + w_max, y_max + h_max), (0, 255, 0), 2)\n",
    "\n",
    "            if self.register_state or self.recognition_state:\n",
    "                roi = thresh[y_max:y_max + h_max, x_max:x_max + w_max]\n",
    "                if roi.size > 0:\n",
    "                    roi = cv2.resize(roi, (88, 128))\n",
    "                    if self.numInGEI < self.gei_fix_num:\n",
    "                        self.gei_current += roi\n",
    "                    self.numInGEI += 1\n",
    "\n",
    "        # -------- After enough frames --------\n",
    "        if self.numInGEI >= self.gei_fix_num:\n",
    "            gei_img = (self.gei_current / self.gei_fix_num).astype(np.uint8)\n",
    "\n",
    "            # -------- Save --------\n",
    "            if self.save_on and self.register_state:\n",
    "\n",
    "                # ðŸ”§ FIX: expand array dynamically\n",
    "                if self.num >= self.gei.shape[0]:\n",
    "                    self.gei = np.vstack([self.gei,\n",
    "                                          np.zeros((1, 128, 88), dtype=np.uint8)])\n",
    "\n",
    "                self.gei[self.num, :, :] = gei_img\n",
    "                Image.fromarray(gei_img).save(f'./gei/gei{self.num:02d}.jpg')\n",
    "                self.name.append(self.id_name.toPlainText())\n",
    "                self.num += 1\n",
    "\n",
    "                dic = {'num': self.num, 'gei': self.gei[:self.num], 'name': self.name}\n",
    "                save_pickle(self.data_path, dic)\n",
    "\n",
    "                self.id_num.setPlainText('%d' % self.num)\n",
    "                self.state_print.setPlainText('Saved!')\n",
    "                self.save_on = False\n",
    "\n",
    "                self.train_model()\n",
    "                self.gei_current = np.zeros((128, 88), np.single)\n",
    "                self.numInGEI = 0\n",
    "\n",
    "            # -------- Recognize (SVM) --------\n",
    "            elif self.recognition_state and self.model is not None:\n",
    "                Xq = gei_img.reshape(1, -1)\n",
    "                probs = self.model.predict_proba(Xq)[0]\n",
    "                idx = np.argmax(probs)\n",
    "                name_rec = self.model.classes_[idx]\n",
    "                conf = probs[idx] * 100\n",
    "\n",
    "                if conf < 60:\n",
    "                    text = \"Unknown\"\n",
    "                else:\n",
    "                    text = f\"{name_rec} ({conf:.1f}%)\"\n",
    "\n",
    "                cv2.putText(frame, text,\n",
    "                            (x_max + 20, y_max + 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)\n",
    "\n",
    "                self.gei_current = np.zeros((128, 88), np.single)\n",
    "                self.numInGEI = 0\n",
    "\n",
    "        # ---------------- Display ----------------\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        qimage = QtGui.QImage(rgb, rgb.shape[1], rgb.shape[0],\n",
    "                              QtGui.QImage.Format_RGB888)\n",
    "        self.video_label.setPixmap(QtGui.QPixmap.fromImage(qimage))\n",
    "\n",
    "        seg = np.repeat(thresh[:, :, np.newaxis], 3, axis=2)\n",
    "        seg[:, :, 0] = 0\n",
    "        seg[:, :, 2] = 0\n",
    "        qseg = QtGui.QImage(seg, seg.shape[1], seg.shape[0],\n",
    "                            QtGui.QImage.Format_RGB888)\n",
    "        self.seg_label.setPixmap(QtGui.QPixmap.fromImage(qseg))\n",
    "\n",
    "    def update_bk(self):\n",
    "        self.bg_sub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=40)\n",
    "        self.state_print.setPlainText(\"Background Updated\")\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        self.capture.release()\n",
    "        event.accept()\n",
    "\n",
    "# ---------------- Run ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    window = GaitDemo()\n",
    "    app.exec_()   # for Jupyter; use sys.exit(app.exec_()) in CMD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5a5eb-eaa2-4e00-afb3-5b9b3334caee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
